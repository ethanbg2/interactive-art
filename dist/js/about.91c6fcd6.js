"use strict";(self["webpackChunkinteractive_art_ui"]=self["webpackChunkinteractive_art_ui"]||[]).push([[443],{2233:function(e,t,i){i.r(t),i.d(t,{default:function(){return p}});var a=i(3396);const n={class:"about"},o=(0,a.uE)("<h1>About SIGCHI</h1><p> SIGCHI is a Special Interest Group within ACM (Association of Computing Machinery), which focuses on Computer-Human Interaction. In weekly meetings (Tuesdays at 6pm), we learn about real-world examples of computer-human interaction in current technology, and then engage in discussions and work on our main project for this year: a tool that produces sound/music from an art/picture, depending on where a person is looking at the artwork. </p><br><h1>Details About This Project </h1><p> This project takes in human-interactive input via an eye tracker, uses the input to select an area of an image, and matches the average color of that area to a specific sound. To accomplish this, our SIG was divided into 4 sub-teams: one dedicated for the eye tracker functionality, one for the user interface, one for infra, and one for image-music conversion.</p><br><h1>Links</h1><p> ACM Website: https://acm.illinois.edu/ </p><p> SIGCHI Website: https://sigchi.acm.illinois.edu/ </p><br><h1> Info About Members</h1><p>Lead: Abhimanyu Thosar, Mitchell Bifeld, Swathi Ram, Jeffrey Tsai</p><p>UI Team: Aditi, Will, Rohith, Karthik, Mari, Ethan, Mitchell</p>",13),r=[o];function s(e,t){return(0,a.wg)(),(0,a.iD)("div",n,r)}var c=i(89);const u={},h=(0,c.Z)(u,[["render",s]]);var p=h}}]);
//# sourceMappingURL=about.91c6fcd6.js.map